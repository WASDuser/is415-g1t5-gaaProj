[
  {
    "objectID": "shinyapp/shinyapp.html",
    "href": "shinyapp/shinyapp.html",
    "title": "Links",
    "section": "",
    "text": "Shiny Application\nGithub Codes"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Abstract",
    "section": "",
    "text": "Abstract\nep\n\n\nLinks\n\nGithub Repo"
  },
  {
    "objectID": "proposal/proposal.html",
    "href": "proposal/proposal.html",
    "title": "Project Proposal",
    "section": "",
    "text": "ShinyGeode\n\n\n\nTheme: Spatial Point Patterns Analysis/Exploratory Spatial Data Analysis\n\n\n\nProject Motivation\nSingaporeans take their home’s low crime rate for granted, often bringing that mindset along when they visit other countries. One of the most popular getaway destinations for us is our neighbour, Malaysia, given the multiple factors of convenience like proximity and the relatively lower cost. However, it will not be wise to assume the same level of safety as we have in Singapore.\nOur project aims to raise awareness about the crimes and safety issues in Malaysia, so that tourists can manage travel risk for their destinations. Spatial Point Pattern Analysis can aid in providing useful insights on the distribution of crime in Malaysia. Exploratory Data Analysis can be utilised to identify hotspots or cold spot areas for crimes of different types, providing travellers with more concrete information when deciding which states to travel to.\n\n\n\nProject Objectives\n\nVisualise the Crime events on a map of the study area\nFigure out if there are any patterns relating the crime type and the spatial units in the study area\nIdentify the crime rates hotspots and clusters\n\n\n\n\nDatasets\n\nCrime Rates working data: Aspatial Data that covers specifics of the crimes committed in the various states.\nShapefile (Administrative level 0-2): Shapefile that contains the admin boundaries of Malaysia\n\n\n\n\nLiterature Review\n\nCriminological Insights: A Comprehensive Spatial Analysis of Crime Hot Spots of Property Offenses in Malaysia’s Urban Centers\n\nObjective:\n\nTo examine patterns in property crimes in Selangor, Kuala Lumpur and Putrajaya from 2015-2020\nTo understand the evolution and dynamics of property crimes\nTo better understand the effects of the National Transformation Programme\n\nGeospatial and Aspatial Data:\n\nStudy areas (Geospatial data) were methodically chosen for their wealth, geopolitical landscape and vibrant city life and attractions. More specifically, the study makes use of the Police Station boundaries in these states.\nProperty Crime incidents and their spatial characteristics served as the aspatial data for the study.\n\nMethods Deployed:\n\nGlobal Measure of Spatial Autocorrelation: Global Moran I’s Statistic\nLocal Measure of Spatial Autocorrelation & Hot spot analysis: Getis-Ord Gi* Statistic\n\nLearnings and Takeaways:\n\nInstead of deploying a wide range of different measures, the study deployed these two methods using different categories (By year, By Location) to gain a more comprehensive understanding of crimes of the this nature\nUsing Police/Jurisdical boundaries to examine crime events is very appropriate and will be useful when chaneling efforts to lower crime rates\n\n\n\n\n\n\nApproach and Methodology\n\nData Preparation\n\nSourcing data and Importing data\nData Wrangling\n\nProcessing imported data to keep only needed information\nRestricting study area\nHandling missing/duplicated data\nCleaning up of data\nExamine data to identify patterns\nJoining of boundary and working data\nPerform a write and read to rds for easier access to variable\n\n\nExploratory Data Analysis (EDA)\n\nVisualising graphs/maps of Crime Rates in various categories\nReveal the spatial distribution of crimes in the study area\n\nGlobal and Local Spatial Autocorrelation\n\nGlobal: Make use of measures such as Moran I’s, Geary C’s to determine if the spatial patterns of the crime events are clustered or are randomly distributed\nLocal: Make use of measures such as Local Moran I’s and Getis-Ord Gi* statistic to identify cold and/or hotspot areas for crime events in our study area.\n\nMapping our results and Interpretation\nConclusion\n\n\n\n\nApplication System Architecture\n\n\n\n\nShiny Storyboard"
  },
  {
    "objectID": "data-wrangling/data_wrangling.html",
    "href": "data-wrangling/data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "pacman::p_load(sf, tidyverse, tmap) # add as needed\n\n\ncrime_sf &lt;- read_csv('data/aspatial/crime_district.csv')\n\n\nglimpse(crime_sf)\n\n\nunique(crime_sf$state)\n\n\nunique(crime_sf$district)\n\n\nunique(crime_sf$category)\n\n\ncat_crime &lt;- ggplot(data=crime_sf, \n             aes(x= `category`)) +\n  geom_bar(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\ncat_crime\n\n\nunique(crime_sf$type)\n\n\nunique(crime_sf$crimes)\n\n\n# overall\nplot(crime_sf$crimes)\n\n\n# Assault (entire M'sia, all types)\ncrime_sf[1:7,]\n\n# Assault by type (entire M'sia)\ncrime_sf[8:56,]\n\n# Property (entire M'sia, all types)\ncrime_sf[57:63,]\n\n# Property by type (entire M'sia)\ncrime_sf[64:98,]\n\n# when extracting rows, filter out the 'all' type and 'All' type, pattern seen above\n\n# potential \n\n\nmsia_adm1 &lt;- st_read(dsn = 'data/geospatial/mys_adm_unhcr_20210211_shp/', layer = 'mys_admbnda_adm1_unhcr_20210211')\nmsia_adm2 &lt;- st_read(dsn = 'data/geospatial/mys_adm_unhcr_20210211_shp/', layer = 'mys_admbnda_adm2_unhcr_20210211')\n\n\ntmap_mode('plot')\n\n\ntm_shape(msia_adm1) + tm_polygons()\n\n\ntm_shape(msia_adm2) + tm_polygons()\n\n—— NEW WRANGLING —–\nLoading in the Packages\n\npacman::p_load(spdep, tmap, sf, ClustGeo, ggpubr, cluster, factoextra, NbClust, heatmaply, corrplot, psych, tidyverse, GGally)\n\nLoad in the aspatial and spatial data.\n\ncrime_district &lt;- read_csv(\"data/aspatial/crime_district.csv\")\npopulation_district &lt;- read_csv(\"data/aspatial/population_district.csv\")\nmsia_adm2_sf &lt;- st_read(dsn = 'data/geospatial', layer = 'mys_admbnda_adm2_unhcr_20210211')\n\nformatting the crime data to only include the state names and their respective districts. Also filter out the rows where the data is aggregated across the crime types, as well as across the districts. Since population data is from 2016-2022, we will also remove the 2023 date rows.\n\ncrime_district &lt;- crime_district %&gt;%\n    filter(year(ymd(date)) &gt;= 2020 & year(ymd(date)) &lt;= 2023) %&gt;% \n    filter(state != \"Malaysia\") %&gt;% \n    filter(category == \"assault\") %&gt;% \n    filter(district != \"All\") %&gt;% \n    filter(type != \"all\") \n\nformatting the population data table to be simpler\n\nlibrary(dplyr)\nlibrary(lubridate)\n\n# population_state_filtered &lt;- \npop_data &lt;- population_district %&gt;%\n    filter(!year(ymd(date)) == 2024) %&gt;% \n    filter(sex == 'both' | sex == 'overall' ) %&gt;% \n    filter(age == 'overall') %&gt;% \n    filter(ethnicity == 'overall') %&gt;% \n    select(-c(4:6))\n\nformatting the district boundary sf by dropping unnecessary columns\n\nadm2_sf &lt;- msia_adm2_sf %&gt;% select(-c(3:5, 8,9,11,12))\n\nUpon visual inspection of the data, we noticed some clear discrepancies among the districts column of all the dataframes. Hence, we decided to check for the unique districts in each of the dataframe.\n\nunique(pop_data$district)\n\n\nunique(adm2_sf$ADM2_EN)\n\n\nunique(crime_district$district)\n\nAs expected, all the dataframes contained different numbers of districts. There were also lots of discrepancies to be handled; differing spelling/naming conventions, splitting of districts into north/south regions, and totally missing districts.\nAs little can be done in salvaging missing districts, we decided to handle the other forms of discrepancies.\nFirst, we will convert all the district names to lowercase letters to eliminate any errors on that front, and to standardise the naming conventions.\n\ncrime_district$district &lt;- tolower(trimws(crime_district$district))\nadm2_sf$ADM2_EN &lt;- tolower(trimws(adm2_sf$ADM2_EN))\npop_data$district &lt;- tolower(trimws(pop_data$district))\n\nSince our main focus was crime data and it was the dataframe that will be mutually connected to both the boundary layer and the population data (phrase better), we will use the districts in the crime dataframe as a guide to formatting the other tables.\nWe first started off by handling the very obvious differences that could be observed through visual inspection as well as through the use of the unique function. We noticed that 2 districts, Johor Bahru and Klang, were split up in the crime dataframe. Hence, we merged these rows and summed up their crime number values.\nstr_detect() function of the stringr package was used to identify rows that contained the given input string. In our case, it was the district name. mutate() was then used to change the values of these rows. Since this produces a new dataframe, another dataframe was created with the rest of the values, before all three were bound together.\n\nlibrary(stringr)\ncrime_johor&lt;- crime_district %&gt;%\n  filter(str_detect(district,\"johor bahru\")) %&gt;%\n  mutate(district = 'johor bahru') %&gt;%\n  group_by(state, district,type, date) %&gt;%\n  summarise(crimes = sum(crimes))\n\ncrime_klang&lt;- crime_district %&gt;%\n  filter(str_detect(district,\"klang\")) %&gt;%\n  mutate(district = 'klang') %&gt;%\n  group_by(state, district,type, date) %&gt;%\n  summarise(crimes = sum(crimes))\n\n\nother_rows &lt;- crime_district %&gt;% \n  filter(!str_detect(district, \"johor bahru\"))\n\ncrime_district &lt;- bind_rows(crime_johor, crime_klang, other_rows) %&gt;% \n  select(-c(6)) %&gt;% \n  mutate(category = 'assault')\n\nNext, we sought to isolate the districts in the other dataframes that were still not matching with that of the crimes dataframe. To do this, a left join of the tables were performed, before the NA rows were extracted and saved in a separate dataframe.\n\npop_crime&lt;- left_join(pop_data, crime_district, by= \"district\")\npop_crime_na&lt;- pop_crime[rowSums(is.na(pop_crime)) &gt; 0,]\n\n\nadm_crime &lt;- left_join(adm2_sf, crime_district, by= c(\"ADM2_EN\" = \"district\"))\nadm_crime_na &lt;- adm_crime[rowSums(is.na(adm_crime)) &gt; 0,]\n\nThis made it easier for identifying dissimilarities, although it was still tedious. After much close comparisons, we managed to identify a handful of spelling and formatting errors across the three dataframes. Hence, we made changes to these rows.\n\ncrime_district&lt;- crime_district%&gt;% \n  mutate(district = ifelse(district == \"cameron highland\", \"cameron highlands\", district)) %&gt;% \n  mutate(district = ifelse(district == \"kuala lipis\", \"lipis\", district)) %&gt;% \n  mutate(district = ifelse(district == \"kota kinabatangan\", \"kinabatangan\", district)) %&gt;% \n  mutate(district = ifelse(district == \"seberang perai tengah\", \"s.p. tengah\", district)) %&gt;% \n  mutate(district = ifelse(district == \"seberang perai utara\", \"s.p. utara\", district)) %&gt;% \n  mutate(district = ifelse(district == \"seberang perai selatan\", \"s.p.selatan\", district)) %&gt;% \n  mutate(district = ifelse(district == \"petaling jaya\", \"petaling\", district)) %&gt;% \n   mutate(district = ifelse(district == \"matu daro\", \"matu\", district))\n  \n\npop_data &lt;- pop_data %&gt;% \n  mutate(district = ifelse(district == \"kulai\", \"kulaijaya\", district)) %&gt;% \n  mutate(district = ifelse(district == \"sp tengah\", \"s.p. tengah\", district)) %&gt;% \n  mutate(district = ifelse(district == \"sp utara\", \"s.p. utara\", district)) %&gt;% \n  mutate(district = ifelse(district == \"sp selatan\", \"s.p.selatan\", district)) %&gt;%\n  mutate(district = ifelse(district == \"cameron highland\", \"cameron highlands\", district))\n\nOnce this was done, we isolated the NA values once again. The remaining districts are districts that were missing from one or more of the dataframes, and would have to be removed from the analysis due to the missing data.\n\npop_crime&lt;- left_join(pop_data, crime_district, by= \"district\")\npop_crime_na&lt;- pop_crime[rowSums(is.na(pop_crime)) &gt; 0,]\n\ndrop_list_pop &lt;- pop_crime_na$district\npop_data &lt;- pop_data %&gt;%\n  filter(!(district %in% drop_list_pop))\n\npop_crime2&lt;-left_join(crime_district, pop_data, by=\"district\")\npop_crime_na2 &lt;-pop_crime2[rowSums(is.na(pop_crime2)) &gt; 0,]\n\ndrop_list_pop &lt;- pop_crime_na2$district\ncrime_district &lt;- crime_district %&gt;%\n  filter(!(district %in% drop_list_pop))\n\n\nadm_crime &lt;- left_join(adm2_sf, crime_district, by= c(\"ADM2_EN\" = \"district\"))\nadm_crime_na &lt;- adm_crime[rowSums(is.na(adm_crime)) &gt; 0,]\n\ndrop_list &lt;- adm_crime_na$ADM2_EN\nadm2_sf &lt;- adm2_sf %&gt;% \n  filter(!(ADM2_EN %in% drop_list))\n\nadm_crime2 &lt;- left_join(crime_district, adm2_sf, by= c(\"district\" = \"ADM2_EN\"))\nadm_crime_na2 &lt;- adm_crime2[rowSums(is.na(adm_crime2)) &gt; 0,]\n\ndrop_list &lt;- adm_crime_na2$ADM2_EN\ncrime_district &lt;- crime_district %&gt;% \n  filter(!(district %in% drop_list))\n\nNow, we would be able to join the dataframes smoothly.\n\nwrite_rds(pop_data, \"data/rds/pop_data.rds\")\nwrite_rds(crime_district, \"data/rds/crime_district.rds\")\nwrite_rds(adm2_sf, \"data/rds/adm2_sf.rds\")\n\n\npop_data&lt;- read_rds(\"data/rds/pop_data.rds\")\ncrime_district &lt;- read_rds(\"data/rds/crime_district.rds\")\nadm2_sf &lt;- read_rds(\"data/rds/adm2_sf.rds\")"
  }
]